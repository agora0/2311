---
layout: post
title: 有效利他主义是什么？它如何引发了硅谷分裂和OpenAI闹剧？
date: 2023-11-23 16:33:02.000000000 +08:00
link: https://cn.wsj.com/amp/articles/%E6%9C%89%E6%95%88%E5%88%A9%E4%BB%96%E4%B8%BB%E4%B9%89%E6%98%AF%E4%BB%80%E4%B9%88-%E5%AE%83%E5%A6%82%E4%BD%95%E5%BC%95%E5%8F%91%E4%BA%86%E7%A1%85%E8%B0%B7%E5%88%86%E8%A3%82%E5%92%8Copenai%E9%97%B9%E5%89%A7-0d86d3f1
categories: wsj
---

<main id="main" role="main">
<div>


</div>
<div itemprop="articleLead" data-sbId="CN-TEC-20231123145526">
    <div>
      <div class="media-object scope-
          header
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-890482?width=540&amp;size=1.5005861664712778 540w, https://images.wsj.net/im-890482?width=620&amp;size=1.5005861664712778 620w, https://images.wsj.net/im-890482?width=639&amp;size=1.5005861664712778 639w, https://images.wsj.net/im-890482?width=860&amp;size=1.5005861664712778 860w, https://images.wsj.net/im-890482?width=860&amp;size=1.5005861664712778&amp;pixel_ratio=1.5 1290w, https://images.wsj.net/im-890482?width=860&amp;size=1.5005861664712778&amp;pixel_ratio=2 1720w, https://images.wsj.net/im-890482?width=860&amp;size=1.5005861664712778&amp;pixel_ratio=3 2580w"
          src="https://images.wsj.net/im-890482?width=860&amp;height=573"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>11月6日，OpenAI首席执行官阿尔特曼在旧金山。</p>
    <p> 图片来源：Justin Sullivan/Getty Images</p>
  </figcaption>
</figure>

          <!-- eventually when we know what this card will be we can change it and leave this one -->
      </div>
    </div>
</div>
<div data-sbId="CN-TEC-20231123145526">

<div>

  <div>
      <p> </p>
              <p><span itemprop="name">
                <a href="https://www.wsj.com/news/author/robert-mcmillan" itemprop="url" rel="author">Robert McMillan</a>
              </span> / </p>
            <p><span itemprop="name">
                <a href="https://www.wsj.com/news/author/deepa-seetharaman" itemprop="url" rel="author">Deepa Seetharaman</a>
              </span></p>

  </div>
    <time>
      2023年11月23日15:15 CST 更新
    </time>
</div>

<div subscriptions-actions subscriptions-display="NOT data.noSharing">
  <div>
    <social-share type="system" width="72" height="24"
      data-param-url="https://cn.wsj.com/articles/有效利他主义是什么-它如何引发了硅谷分裂和openai闹剧-0d86d3f1">
    </social-share>
  </div>
</div>


<div subscriptions-section="content">
</div>
<div subscriptions-section="content-not-granted">
</div>



<section subscriptions-section="content">
      <p>过去几年，被称为有效利他主义的社会运动在硅谷大大小小的AI公司中间制造了裂痕，信奉者与怀疑者彼此对立。</p>
      <p>OpenAI内爆显示了这项运动的影响力，而CEO阿尔特曼(Sam Altman)凯旋而归也暴露了实打实的局限，说明在过去一年中，这一自带分裂属性的哲学理念没少带来创伤。</p>
      <p>就在有效利他主义最著名的支持者山姆·班克曼-弗里德(Sam Bankman-Fried)被判犯有诈骗罪的几周之后，OpenAI的风波再次打击了这项运动；该运动认为，精心构建的AI系统若注入正确的人类价值观，将产生一个黄金时代——而如果做不到这一点，则可能带来世界末日般的后果。</p>
      <p>一年前发布了ChatGPT的OpenAI，其成立在一定程度上基于有效利他主义的原则；这是一种广泛的社会和道德哲学，影响着硅谷和其他地方的AI研究社区。一些追随者住在私人的集体宿舍里，在那里他们可以集思广益，进行哲学辩论，还可以玩一种被称为“疯人院棋”(Bughouse) 的四人对弈国际象棋变体来放松自己。该运动包括致力于动物权益和气候变化的人，他们从理性主义哲学家、数学家和未来预测者那里汲取灵感。</p>
      <div> <p>有效利他主义者认为，在科技巨头数以亿美元计资助的推动下，一窝蜂地去搞AI可能会毁灭人类。他们在AI发展问题上更注重安全而非速度。这场运动有其偏狭性和多面性，但有一个共同的信念贯穿其中，他们信奉的是要在世上行善——即使这仅仅意味着先赚大钱再把钱给予值得帮助的人。这场运动的参与者有些是生成式AI热潮的弄潮儿。</p>
      <p>据了解相关争端内情的人士称，上周五遭董事会解职的阿尔特曼与该公司首席科学家兼董事会成员Ilya Sutskever有冲突，事涉一些与有效利他主义关切相呼应的AI安全议题。</p>
      <p>与此次董事会“政变”牵头人Sutskever一起投票的是董事会成员Tasha McCauley和Helen Toner，前者是一位科技公司高管，还是有效利他主义慈善机构Effective Ventures的董事会成员，后者是乔治敦大学(Georgetown University)安全与新兴技术中心(Center for Security and Emerging Technology)的高管，该中心得到一个致力于有效利他主义事业的慈善机构的支持。知情人士说，他们占到将阿尔特曼解职所需四票中的三票。董事会称阿尔特曼未能做到“始终如一地坦诚”。</p>
      <p>该公司周三宣布，阿尔特曼将恢复CEO职位，Sutskever、McCauley和Toner将被替换。支持放慢AI发展速度、并被聘为临时CEO的技术高管Emmett Shear则被解职。</p>
      <p>阿尔特曼被罢免引发了该公司员工的大面积反抗，这场反抗威胁到了OpenAI的未来。约770名员工中有700多人要求阿尔特曼回归，并威胁要跳槽到OpenAI最大的投资者微软。Sutskever周一表示，他对自己的投票感到后悔。</p>
      <p>风险投资家、OpenAI投资人Vinod Khosla在The Information的一篇评论文章中写道：“OpenAI的董事会成员对‘有效利他主义’的信奉及错误应用，可能会阻碍世界享受AI的巨大红利。”</p>
      <p>阿尔特曼今年春天在全球巡回演讲，警告AI可能造成严重危害。他也称有效利他主义是一种“存在严重缺陷的运动”，会有“非常奇怪的系统涌现出来”。</p>
      <p>有效利他主义社区花费了巨资来宣传AI构成生存风险的观点。得克萨斯大学奥斯汀分校(University of Texas, Austin)的计算机科学家Scott Aaronson在OpenAI从事AI安全研究，他表示，正是ChatGPT的发布引发了人们对AI飞速发展的广泛关注。他说，这款聊天机器人令人吃惊的能力让以前对此不以为然的人们感到担忧。</p>
      <p>这场运动已经在科技行业的科学家、投资者和高管队伍中传播开来，他们竞相创造AI系统，以模仿并最终超越人类的能力。这场运动的参与者认为，AI可以带来全球繁荣，但首先必须防止它造成破坏。</p>
      <p>谷歌(Google)和其他公司正试图率先推出能与人脑媲美的AI系统。这些公司在很大程度上将AI视为一种工具来推动工作和经济发展，并从中获取巨额利润。</p>
      <p>支持该运动的知名人士包括Facebook的联合创始人Dustin Moskovitz、Skype的亿万富翁创始人Jann Tallinn，他们承诺为有效利他主义研究提供数以十亿美元计资金。班克曼-弗里德伏法之前，也承诺提供数以十亿美元计资金。马斯克(Elon Musk)曾称有效利他主义的联合创始人William MacAskill的著作“与我的理念非常吻合”。</p>
      <div class="media-object scope-
          inline
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-890487?width=540&amp;size=1.5005861664712778 540w, https://images.wsj.net/im-890487?width=620&amp;size=1.5005861664712778 620w, https://images.wsj.net/im-890487?width=639&amp;size=1.5005861664712778 639w, https://images.wsj.net/im-890487?width=700&amp;size=1.5005861664712778 700w, https://images.wsj.net/im-890487?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-890487?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-890487?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=3 2100w"
          src="https://images.wsj.net/im-890487?width=700&amp;height=466"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>2018年4月12日，温哥华，有效利他主义的联合创始人哲学家Will MacAskill在TED2018上发表演讲。</p>
    <p> 图片来源：Lawrence Sumulong/Getty Images</p>
  </figcaption>
</figure>

          <!-- eventually when we know what this card will be we can change it and leave this one -->
      </div>
      <p>风险投资公司Andreessen Horowitz的联合创始人Marc Andreessen和初创企业孵化器Y Combinator的CEO Garry Tan对这一运动提出了批评。Tan称这是一种没有实质意义的“美德信号哲学”，应予以摒弃，以“解决真正的问题，创造人类的富足”。</p>
      <p>研究员Shazeda Ahmed在普林斯顿大学(Princeton University)领导一个研究该运动的团队。Ahmed说，有效利他主义者对AI将毁灭人类的急剧恐惧，“影响了他们接受来自该文化以外的批评的能力”。Ahmed说：“对于所有试图解决某个尖锐问题的群体来说，这肯定都不是好事。”</p>
      <p>OpenAI的动荡揭露了硅谷的一场幕后较量，相信市场力量的人与认为道德、理性、数学和精巧的机器应该引领未来的有效利他主义者形成了对峙。</p>
      <p>对这一运动的描述基于对50多位高管、研究人员、投资者、现任和前任有效利他主义者的采访，以及有效利他主义领域的公开演讲、学术论文和其他公开资料。</p>
      <p><strong>回形针恶作剧</strong></p>
      <p>去年秋天的一天，数以千计做成OpenAI徽标形状的回形针出现在该公司旧金山办公室。似乎没有人知道它们来自何处，但每个人都知道它们意味着什么。</p>
      <div class="media-object scope-
          inline
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-890582?width=540&amp;size=0.6670140698280355 540w, https://images.wsj.net/im-890582?width=620&amp;size=0.6670140698280355 620w, https://images.wsj.net/im-890582?width=639&amp;size=0.6670140698280355 639w, https://images.wsj.net/im-890582?width=700&amp;size=0.6670140698280355 700w, https://images.wsj.net/im-890582?width=700&amp;size=0.6670140698280355&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-890582?width=700&amp;size=0.6670140698280355&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-890582?width=700&amp;size=0.6670140698280355&amp;pixel_ratio=3 2100w"
          src="https://images.wsj.net/im-890582?width=700&amp;height=1049"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>在旧金山 OpenAI办公室投下的其中一枚回形针。</p>
  </figcaption>
</figure>

          <!-- eventually when we know what this card will be we can change it and leave this one -->
      </div>
      <p>回形针已成为AI潜在风险的一个象征。这源于一种假想情境，涉及一个被告知要制造尽可能多回形针的AI系统可能为追求产量最大化而毁灭整个人类。</p>
      <p>这个恶作剧是同城竞争对手Anthropic的一名员工所为，而Anthropic本身也受困于AI安全问题引发的分歧。</p>
      <p>2021年初，OpenAI的顶级研究科学家Dario Amodei从公司离职，公司的几位高管也加入了他的行列。他们创办了Anthropic，这是一家对有效利他主义者友好的AI研究公司。</p>
      <p>班克曼-弗里德曾是Anthropic最大的投资者之一，并支持该公司的使命，即更看重AI的安全性，而非增长和利润。</p>
      <p>对未来AI系统的恐惧并没有阻止那些担心安全的人尝试建立通用人工智能(AGI)，这是一种与人脑相媲美或超越人脑的先进系统。</p>
      <p>去年12月，在OpenAI的节日派对上，Sutskever在旧金山加州科学馆(California Academy of Science)向数百名员工和嘉宾发表了讲话。 那里离科学馆的斑马、羚羊和狮子填充模型不远。</p>
      <p>首席科学家Sutskever说：“我们的目标是制造一个热爱人类的AGI。”</p>
      <p>“感受AGI”，他说。“跟我念——感受AGI。”</p>
      <p>有效利他主义者说，他们可以构筑更安全的AI系统，因为他们愿意投资于所谓的对齐(alignment)：确保员工可以控制其创造的AI技术，并确保AI技术符合一系列人类价值观。迄今为止，还没有哪家AI公司说过这些价值观应该是什么。</p>
      <p>OpenAI最近表示，在未来四年将把自身五分之一的计算资源投入到该公司所说的“超级对齐”(superalignment)上；超级对齐是由Sutskever牵头的一项工作。知情人士称，该团队已在打造的东西包括一个可以对AI系统进行研究的AI衍生“科学家”。</p>
      <div class="media-object scope-
          inline
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-890488?width=540&amp;size=1.5005861664712778 540w, https://images.wsj.net/im-890488?width=620&amp;size=1.5005861664712778 620w, https://images.wsj.net/im-890488?width=639&amp;size=1.5005861664712778 639w, https://images.wsj.net/im-890488?width=700&amp;size=1.5005861664712778 700w, https://images.wsj.net/im-890488?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-890488?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-890488?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=3 2100w"
          src="https://images.wsj.net/im-890488?width=700&amp;height=466"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>6月5日，阿尔特曼（图左）和OpenAI首席科学家Ilya Sutskever在特拉维夫发表讲话。</p>
    <p> 图片来源：JACK GUEZ/Agence France-Presse/Getty Images</p>
  </figcaption>
</figure>

          <!-- eventually when we know what this card will be we can change it and leave this one -->
      </div>
      <p>一些沮丧的员工表示，对AGI和对齐的关注已导致用于解决更紧迫问题的资源减少，比如开发者滥用、欺诈以及可能影响2024年大选的恶意使用AI等问题。他们说，资源方面的差异反映了有效利他主义的影响。</p>
      <p>据熟悉OpenAI的人士称，虽然OpenAI正在开发自动化工具来捕捉滥用行为，但并没有为这项工作雇用很多调查人员。该公司也没有多少员工负责监控其开发者平台，有200多万的研究人员、公司和其他开发者在使用该平台。</p>
      <p>该公司最近雇人评估OpenAI技术在美国2024年大选中的作用。有专家警告说，AI生成的图像有可能误导选民。</p>
      <p>OpenAI的一位发言人说，该公司已投入巨资来审核其产品，并有几个团队来管理短期风险。该公司表示，还投入了大量资源训练AI模型，以避免产生有害内容。</p>
      <div class="media-object scope-
          inline
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-890583?width=540&amp;size=1.5005861664712778 540w, https://images.wsj.net/im-890583?width=620&amp;size=1.5005861664712778 620w, https://images.wsj.net/im-890583?width=639&amp;size=1.5005861664712778 639w, https://images.wsj.net/im-890583?width=700&amp;size=1.5005861664712778 700w, https://images.wsj.net/im-890583?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-890583?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-890583?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=3 2100w"
          src="https://images.wsj.net/im-890583?width=700&amp;height=466"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>9月20日，Anthropic联合创始人兼首席执行官Dario Amodei在旧金山举行的TechCrunch Disrupt 2023大会上。</p>
    <p> 图片来源：Kimberly White/Getty Images</p>
  </figcaption>
</figure>

          <!-- eventually when we know what this card will be we can change it and leave this one -->
      </div>
      <p>据谷歌的现任和前任员工称，今年该公司合并旗下两个AI部门DeepMind和Google Brain的做法引发了对如何应用有效利他主义原则的意见分歧。</p>
      <p>DeepMind联合创始人Demis Hassabis负责两个部门合并后的业务。Hassabis长期以来一直雇用支持有效利他主义运动的人。</p>
      <p>知情人士透露，Google Brain的员工称，他们在很大程度上忽略了有效利他主义，而是探索AI的实际用途以及AI工具可能被滥用的问题。</p>
      <p>Google Brain的一位前员工将与DeepMind的合并比作一场包办婚姻，说这导致很多人在Brain很尴尬。</p>
      <p><strong>AI造成灾难的估计概率</strong></p>
      <p>21岁的AI安全研究员Arjun Panickssery与其他有效利他主义者住在Andromeda House，这是一栋三层楼住宅，有五间卧室，距离加州大学伯克利分校(University of California, Berkeley)校园有几个街区。</p>
      <p>他们举办晚宴，来访者有时会被要求透露他们估计AI导致灾难的几率，也就是P(doom)。</p>
      <p>Panickssery说，在湾区，加州大学伯克利分校是有效利他主义的一个中心。有些房子划出了AI禁止区，以便让疲于不断谈论AI话题的人们得到解脱。</p>
      <div class="media-object scope-
          inline
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-890647?width=540&amp;size=0.764179104477612 540w, https://images.wsj.net/im-890647?width=620&amp;size=0.764179104477612 620w, https://images.wsj.net/im-890647?width=639&amp;size=0.764179104477612 639w, https://images.wsj.net/im-890647?width=700&amp;size=0.764179104477612 700w, https://images.wsj.net/im-890647?width=700&amp;size=0.764179104477612&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-890647?width=700&amp;size=0.764179104477612&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-890647?width=700&amp;size=0.764179104477612&amp;pixel_ratio=3 2100w"
          src="https://images.wsj.net/im-890647?width=700&amp;height=916"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>加利福尼亚州伯克利Andromeda House的国际象棋比赛。</p>
    <p> 图片来源：Tzu Kit Chan</p>
  </figcaption>
</figure>

          <!-- eventually when we know what this card will be we can change it and leave this one -->
      </div>
      <p>据Open Philanthropy网站上的信息，其时任首席执行官Holden Karnofsky一度与两位OpenAI高管同住。Open Philanthropy是一家支持有效利他主义事业的非营利机构，自2015年以来已累计捐出3.27亿美元，其中包括捐给OpenAI的3,000万美元。</p>
      <p>Karnofsky与Daniela Amodei（Anthropic现任总裁）订婚时， 两人与Amodei的兄弟Dario（Anthropic现任首席执行官）是室友。</p>
      <p>2017年8月，Karnofsky和Daniela Amodei举办了一场以有效利他主义为主题的结婚仪式。婚礼来宾被鼓励向Karnofsky的有效利他主义慈善机构GiveWell捐款，并事先阅读德国哲学家哈贝马斯(Jurgen Habermas)一部457页的巨着。</p>
      <p>当时这对新人在婚礼网站上写道：“这对于理解我们的婚礼是必要的背景。”</p>
      <p>有效利他主义运动可以追溯到大约20年前，当时牛津大学(Oxford University)的一群哲学家以及被他们认定的“超级铁杆行善者”试图找到一个营销术语来推广他们的功利版慈善事业。</p>
      <p>拥趸者们的理念是，要把他们花时间做的好事利益最大化。他们可以尽可能多地赚钱，然后将其中大部分捐出去，用于解决政府和传统非营利组织所忽视的或尚未解决的问题。他们专注于实践那些每花费一美元就能产生最大影响或帮助最多人的点子。</p>
      <p>本月被定罪的班克曼-弗里德表示，他积累财富的目的只是为了把大部分财富捐出去。</p>
      <p>从2014年前后开始，有效利他主义者的关注点转向人类被先进AI系统毁灭的风险，认为这种危险的程度堪比气候变化。这种启示与瑞典哲学家Nick Bostrom写的《超级智能》（Superintelligence）一书的出版彼此呼应，用来比拟AI危险的所谓“回形针”理论也随之流行起来。</p>
      <div class="media-object scope-
          inline
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-890504?width=540&amp;size=1.5005861664712778 540w, https://images.wsj.net/im-890504?width=620&amp;size=1.5005861664712778 620w, https://images.wsj.net/im-890504?width=639&amp;size=1.5005861664712778 639w, https://images.wsj.net/im-890504?width=700&amp;size=1.5005861664712778 700w, https://images.wsj.net/im-890504?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-890504?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-890504?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=3 2100w"
          src="https://images.wsj.net/im-890504?width=700&amp;height=466"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>3月30日，FTX创始人山姆-班克曼-弗里德（图中）抵达纽约联邦法院。</p>
    <p> 图片来源：ed jones/Agence France-Presse/Getty Images</p>
  </figcaption>
</figure>

          <!-- eventually when we know what this card will be we can change it and leave this one -->
      </div>
      <p>自那以后，有效利他主义者形成了在线社区网络，他们在这里交流工作建议、争论哲学并提供预测。附属的非营利机构和学生团体组织当地聚会和会议，专注于使用理性、经济学和数学来解决全球最大的问题。</p>
      <p>这些在世界各地举行的聚会和活动通常不对外界开放。最近在纽约举行的一次有效利他主义会议的组织者拒绝了《华尔街日报》(The Wall Street Journal)一名记者的参会请求，并在一封电子邮件中表示，“参会门槛很高”。</p>
      <p>这封邮件建议该记者“多花一些时间与有效利他主义团体接触，会有裨益”。</p>
      </div>
</section>

</div>
      </main>

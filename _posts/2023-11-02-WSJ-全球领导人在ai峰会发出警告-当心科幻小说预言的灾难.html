---
layout: post
title: 全球领导人在AI峰会发出警告：当心科幻小说预言的灾难
date: 2023-11-02 12:33:03.000000000 +08:00
link: https://cn.wsj.com/amp/articles/%E5%85%A8%E7%90%83%E9%A2%86%E5%AF%BC%E4%BA%BA%E5%9C%A8ai%E5%B3%B0%E4%BC%9A%E5%8F%91%E5%87%BA%E8%AD%A6%E5%91%8A-%E7%A7%91%E5%B9%BB%E5%B0%8F%E8%AF%B4%E9%87%8C%E7%9A%84%E7%81%BE%E9%9A%BE%E6%88%96%E8%83%BD%E6%88%90%E7%9C%9F-e963fb09
categories: wsj
---

<main id="main" role="main">
<div>


</div>
<div itemprop="articleLead" data-sbId="CN-TEC-20231102105230">
    <div>
      <div class="media-object scope-
          header
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-879352?width=540&amp;size=1.4988290398126465 540w, https://images.wsj.net/im-879352?width=620&amp;size=1.4988290398126465 620w, https://images.wsj.net/im-879352?width=639&amp;size=1.4988290398126465 639w, https://images.wsj.net/im-879352?width=860&amp;size=1.4988290398126465 860w, https://images.wsj.net/im-879352?width=860&amp;size=1.4988290398126465&amp;pixel_ratio=1.5 1290w, https://images.wsj.net/im-879352?width=860&amp;size=1.4988290398126465&amp;pixel_ratio=2 1720w, https://images.wsj.net/im-879352?width=860&amp;size=1.4988290398126465&amp;pixel_ratio=3 2580w"
          src="https://images.wsj.net/im-879352?width=860&amp;height=574"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>周三，英国科学、创新和技术大臣米歇尔･唐兰等全球各国官员和技术高管参与了在英国举行的人工智能安全峰会。</p>
    <p> 图片来源：chris j ratcliffe/pool/Shutterstock</p>
  </figcaption>
</figure>

          <!-- eventually when we know what this card will be we can change it and leave this one -->
      </div>
    </div>
</div>
<div data-sbId="CN-TEC-20231102105230">

<div>

  <div>
      <p> </p>
              <p><span itemprop="name">
                <a href="https://www.wsj.com/news/author/sam-schechner" itemprop="url" rel="author">Sam Schechner</a>
              </span></p>

  </div>
    <time>
      2023年11月2日11:45 CST 更新
    </time>
</div>

<div subscriptions-actions subscriptions-display="NOT data.noSharing">
  <div>
    <social-share type="system" width="72" height="24"
      data-param-url="https://cn.wsj.com/articles/全球领导人在ai峰会发出警告-科幻小说里的灾难或能成真-e963fb09">
    </social-share>
  </div>
</div>


<div subscriptions-section="content">
</div>
<div subscriptions-section="content-not-granted">
</div>



<section subscriptions-section="content">
      <p>二战密码破译人员曾在英国乡村的一座庄园里破解了纳粹的恩尼格玛(Enigma)密码机，而今世界各国领导人在这里承诺共同努力，以降低一项他们认为也构成严重威胁的技术所带来的风险。</p>
      <p>领导人们说，最先进的人工智能(AI)可能会在网络安全和生物科技等领域造成灾难性风险，甚至脱离人类的掌控。</p>
      <p>英国科学、创新和技术部大臣米歇尔･唐兰(Michelle Donelan)引用一位曾在该庄园工作过的密码破译人员的话说：“有时值得认真对待科幻小说。”</p>
      <p>此次为期两天的峰会于周三在伦敦郊外约40英里的地方拉开帷幕，在峰会开幕式上发表的一份声明中，美国、中国和其他20几个国家承诺将加强合作，共同评估未来的AI系统（称为模型）所带来的风险，并考虑制定法律框架来管理这些系统的部署；这些系统比现在的AI系统更加强大。</p>
      <div> <p>联合声明说：“这些AI模型最重要的能力有可能造成严重、甚至灾难性的伤害，无论是蓄意的还是无意的。”声明中提到的原因是强大的AI系统有可能被不良分子滥用，或者人类因无法完全理解且很难预测甚而失去对AI系统的控制。</p>
      <p>这一承诺是国际社会首次针对AI风险发出重要声明，对强大的新AI模型可能给人类带来生存风险的警告做出了回应。</p>
      <p>关于应多么重视这些警告以及如何应对这些警告的辩论是本次会议的主要议程，与会者包括美国副总统哈里斯(Kamala Harris)率领的美国代表团，以及包括马斯克(Elon Musk)和OpenAI首席执行官Sam Altman在内的领先AI企业的高管。</p>
      <p>这两位科技高管都曾对他们所说的AI潜在的破坏能力<a href="https://cn.wsj.com/articles/CN-TEC-20230531111020" target="_blank" >提出过警告</a>；他们领导的公司正努力打造各自的AI。</p>
      <p>包括Meta Platforms政策执行官、英国前副首相克莱格(Nick Clegg)在内的其他人周二在公开场合表示，这些猜测出来的风险分散了人们对当前问题的注意力，比如保护选举免受AI制作的虚假视频的影响。</p>
      <p>克莱格说："如果花太多时间去担心远在未来的事情，就会减少对眼前风险的关注。”</p>
      <div class="media-object scope-
          inline
">
          <figure>
      <div>
        <img
          srcset="https://images.wsj.net/im-879353?width=540&amp;size=1.5005861664712778 540w, https://images.wsj.net/im-879353?width=620&amp;size=1.5005861664712778 620w, https://images.wsj.net/im-879353?width=639&amp;size=1.5005861664712778 639w, https://images.wsj.net/im-879353?width=700&amp;size=1.5005861664712778 700w, https://images.wsj.net/im-879353?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=1.5 1050w, https://images.wsj.net/im-879353?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=2 1400w, https://images.wsj.net/im-879353?width=700&amp;size=1.5005861664712778&amp;pixel_ratio=3 2100w"
          src="https://images.wsj.net/im-879353?width=700&amp;height=466"
          layout="responsive"
          placeholder
          alt="">
        </img>
      </div>
      <figcaption>
        <p>在周三开始的为期两天的英国AI安全峰会上，世界各国领导人承诺将共同努力降低人工智能的风险。</p>
    <p> 图片来源：chris j ratcliffe/pool/Shutterstock</p>
  </figcaption>
</figure>

          <!-- eventually when we know what this card will be we can change it and leave this one -->
      </div>
      <p>美国周三表示将成立一个AI安全中心，隶属于商务部，并且承诺将与英国同行展开合作，制定衡量AI系统能力的基本标准，并根据拜登政府的新行政令来收集AI公司报告的数据。</p>
      <p>英国还宣布了明年在韩国和法国举办AI安全峰会的远期计划。</p>
      <p>西方官员和行业高管认为，中国参与此次峰会是件值得注意的事，因为一些人担心AI可能会变成世界超级大国之间军备竞赛的一部分。</p>
      <p>英国首相苏纳克(Rishi Sunak)在上周的一次演讲中说：“如果不至少尝试让全球所有领先的AI大国参与进来，就不可能产生严肃的AI战略。”</p>
      <p>中国科学技术部副部长吴朝晖在这次峰会的开幕式上说，中国支持国际社会建立AI测试和评估系统的工作。</p>
      <p>长期以来，机器无所不能带来的AI末日论威胁一直是流行文化中令人着迷的议题。但自从OpenAI的ChatGPT问世以来，这也成为了一个争论话题，即决策者应确定哪些优先事项。ChatGPT展示了这项新技术令人不可思议的能力，对几乎任何主题的问题都能给出似乎可信又表述流畅的答案。</p>
      <p>哈里斯在周三的一次演讲中说，专家们应该扩大对AI安全的定义，关注更广泛的风险，包括她所说的已经存在的社会危害，比如偏见、歧视或传播错误信息的能力。本周早些时候签署的一项美国行政令针对了其中的几个问题，此次峰会的组织者周三也提到了这些问题。</p>
      <p>一些数字权利和工会组织也呼应了这些担忧。这些组织周一发表了一封公开信，对该峰会的优先事项提出了批评。</p>
      <p>“这关系到你会不会被算法炒鱿鱼，或者会不会因为你的身份或邮编而被不公平地进行贷款分析，”信中写道。“随着少数几家大型科技公司正在攫取更大权力和影响力，小企业和艺术家正在被挤出市场，创新正在被扼杀。”</p>
      <p>与此同时，一些AI研究人员担心他们所认为的AI会带来的灾难性风险，敦促决策者控制最先进AI系统的开发。</p>
      <p>非营利组织未来生命研究所(Future of Life Institute)正在前述峰会上推动制定具有约束力的规则，以迫使公司证明其系统是安全的，不会面临潜在的生存危险，而不是由政府监管机构务必证明一个系统存在威胁。未来生命研究所在春季组织了一封联名信，呼吁<a href="https://cn.wsj.com/articles/CN-TEC-20230330072855" target="_blank" >暂停开发</a>最先进AI系统六个月。</p>
      <p>不过，麻省理工学院教授、未来生命研究所所长Max Tegmark在此次峰会前表示，他认为发表一份声明就是一种进步。</p>
      <p>他说，即使是一份仅仅承认AI系统存在真正风险的联合声明，也是个重大进步。</p>
      </div>
</section>

</div>
      </main>
